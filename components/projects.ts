export const projects = [
    {
        id: 1,
        img: '/images/projects/setqr-ss.png',
        title: 'setQR',
        subtitle: 'web app used to generate custom QR codes',
        livelink: 'https://setqr.netlify.app',
        details: `setQR is a powerful website that makes it easy for users to create
         customized QR codes that stand out from the crowd. With setQR, you can generate
          unique QR codes that incorporate your own logo or other design elements, making
           them perfect for use in marketing campaigns, promotions, or any other situation
            where you want to grab people's attention.

        Using setQR is simple and intuitive. Just visit the website, input the information
         you want to encode into the QR code, and upload your logo or choose from a library
          of graphics to use as a design element. The website's powerful software will generate
           a high-quality QR code that's tailored to your specifications, and you can download 
           the image file for use in your own projects.
        
        But that's not all setQR has to offer. For developers, setQR provides an API interface
         that allows them to make calls to the website's server and generate customized QR codes
          on the fly. With just an API key and ID, developers can integrate QR code creation into
           their own applications or services and offer a seamless user experience to their own users.
        
        Overall, setQR is a must-have tool for anyone who wants to take their QR code game to the
         next level. Whether you're a marketer, a business owner, or a developer, setQR makes it 
         easy to create unique, eye-catching QR codes that get noticed. Give it a try today and
          see what all the fuss is about!`
    },
    {
        id: 2,
        img: '/images/projects/taskguru-ss.png',
        title: 'TASKGURU',
        subtitle: 'web app used for managing your tasks',
        livelink: 'https://mytaskguru.netlify.app',
        details: `TaskGuru is a powerful task management website that allows 
        you to easily keep track of your to-do lists, schedule your tasks and stay 
        organized. With TaskGuru, you can sign up for a free account and log in anytime to
         access your private task list, edit labels, mark tasks as completed, and delete them.
         One of the standout features of TaskGuru is its ability to help you manage your tasks 
         efficiently. You can mark tasks as completed as you go along, so you can easily keep 
         track of your progress and feel a sense of accomplishment as you work through your list. 
         You can also delete tasks that are no longer relevant, keeping your task list streamlined
          and focused on what really matters. TaskGuru is perfect for busy individuals who want 
          to stay on top of their tasks and achieve their goals. Whether you're a student, a professional,
           or just someone who wants to stay organized, TaskGuru is the perfect tool for you. Sign up 
           for a free account today and start managing your tasks like a pro!`
    },
    {
        id: 3,
        img: '/images/projects/linkedin-clone.png',
        title: 'linkedIn clone',
        subtitle: 'Basic UI clone of linked equipped with authentication and database using firebase ',
        livelink: 'https://devsnacks-linkedin-clone.app',
        details: `In this project, I aimed to recreate the familiar and user-friendly interface of LinkedIn while incorporating modern web technologies. By leveraging the power of React, I created a dynamic and interactive user interface that delivers a seamless browsing experience.

        To ensure a secure and reliable authentication system, I integrated Firebase Authentication. This allows users to create accounts, log in, and securely access their personalized profiles. By leveraging Firebase Firestore, a scalable and real-time database, I implemented robust data storage and retrieval functionalities for user profiles, connections, and other essential features.
        
        Throughout the development process, I focused on delivering a high-performance application with smooth transitions and responsive design. Leveraging the Redux library, I effectively managed the application's state, providing efficient data flow and enhancing overall performance.
        
        By building this LinkedIn UI clone, I aimed to showcase my proficiency in frontend development, UI design, and integration of powerful technologies. The project demonstrates my ability to create engaging user interfaces, implement secure authentication mechanisms, and utilize cutting-edge tools and frameworks to deliver outstanding web applications.`
    },
    {
        id: 4,
        img: '/images/projects/mutanos-ss.png',
        title: 'Mutanos',
        subtitle: 'landing page done for an imaginary restaurant',
        livelink: 'https://mutanos.netlify.app',
        details: `Mutanos is a dummy landing page done for an imaginary restaurant 
        it assumes a format which would be similar to what an actual restaurant website would look like
        on loading the webpage, the first thing the user would see would be the meal of the day, the image of the dish and the
         price and a link to order the meal of the day. The next section shows the two differnet categories of thr dishes served at the restaurant
         which are the local and international dishes, clicking on the cards will lead you to seeing all the various dishes available.
         the last section contains brief introduction of the lead chef at the restaurant.`
    },
    {
        id: 5,
        img: '/images/projects/code.png',
        title: 'taskguru-api',
        subtitle:'API for taskguru',
        codeLink: 'https://github.com/pappitito/taskguru-API',
        details: `The TaskGuru API is a robust RESTful API that allows developers to create,
         read, update and delete user accounts and tasks programmatically. Built using the 
         popular Express.js web framework and the scalable MongoDB database, the TaskGuru API is
          designed to be flexible, efficient and easy to use.

        Developers can make HTTP requests to the TaskGuru API using a wide range of programming
         languages and tools, making it easy to integrate task management functionality into their 
         own applications and services. The API supports common HTTP verbs such as GET, POST, PUT 
         and DELETE, allowing developers to perform all the CRUD (Create, Read, Update, Delete) 
         operations on user accounts and tasks.
        
        The API is secured with industry-standard authentication mechanisms, including JSON Web 
        Tokens (JWT), ensuring that only authorized users can access and manipulate their tasks. 
        The API also includes input validation and error handling mechanisms, helping developers 
        catch and handle errors gracefully.
        
        Overall, the TaskGuru API is a powerful tool that enables developers to extend 
        the functionality of TaskGuru and integrate it into their own applications and services.
         Whether you're building a mobile app, a web application or an IoT device, the TaskGuru API
          provides a flexible and scalable solution for managing user accounts and tasks programmatically.`,
    },
    {
        id: 6,
        img: '/images/projects/code.png',
        title: 'setQR-API',
        subtitle: 'backend powering the setQR web app',
        codeLink: 'https://github.com/pappitito/setQR-api',
        details: `An API (Application Programming Interface) for
         creating customized QR codes is a software interface that
          enables developers to integrate the functionality of generating
           QR codes into their applications or websites. This API allows 
           users to customize their QR codes by adding a logo, changing the
            color scheme, or altering the shape and size of the code to fit 
            their specific needs.

        Using this API, developers can easily generate high-quality QR
         codes that are designed to match their branding and marketing efforts.
          With the ability to customize the QR code's appearance, businesses can
           create codes that are more visually appealing and engaging for their
            customers, while still maintaining the functionality of a traditional
             QR code.
        
        The API can be easily integrated into a variety of applications, including
         mobile apps, websites, and e-commerce platforms, making it a versatile
          tool for businesses of all sizes. By using this API, businesses can
           enhance their marketing efforts and provide a more engaging and 
           interactive experience for their customers. 

           When developers sign up for an API that provides the functionality of creating
            customized QR codes, they are usually provided with an API key and ID. These 
            are unique identifiers that allow the API to verify the authenticity of the
             request being made. To make a QR code creation request, the developer must 
             provide their API key and ID in the query parameters of the API request. This 
             enables the API to authenticate the request and ensure that it is being made by
              an authorized user. By requiring an API key and ID for each request, 
              the API provider can monitor and control access to the API. 
              This helps to prevent unauthorized usage and ensures that only 
              approved requests are processed, protecting the integrity and 
              security of the service. Overall, the provision of an API key and ID
               is a standard security measure used by many APIs to authenticate requests and 
               ensure that only authorized users can access the service.
           
           `,
    },
    {
        id: 7,
        img: '/images/projects/wbt-ss.png',
        title: 'web trade journal',
        subtitle: 'online trading journal for traders',
        livelink: '',
        details: `Web Trade Journal is a powerful online platform designed to help financial
         market traders document their trades and track their progress over time. The platform
          is intuitive and easy to use, allowing traders to quickly and easily log their trades 
          and monitor their performance.

        With Web Trade Journal, traders can document a range of properties for each trade, including
         the open price, close price, stop loss, take profit, risk to reward ratio, strategy utilized,
          and instrument traded. This comprehensive view of each trade allows traders to identify patterns
           in their trading behavior and make informed decisions.
        
        The platform is designed with privacy and security in mind. Each trader has their own private journal
         that is only accessible with authentication. This ensures that each trader's data is kept secure and confidential.
        
        Web Trade Journal provides traders with valuable insights into their trading performance.
         The platform tracks the number of trades won, lost, or break even, as well as the trader's win
          rate and best strategy. This data can be used to help traders identify areas for improvement and 
          optimize their trading strategies.
        
        The platform is also highly customizable. Traders can export their data in a range of formats, allowing
         them to create custom reports and analyze their trading performance in greater detail.
        
        Overall, Web Trade Journal is an essential tool for any financial market trader who wants to improve
         their trading strategies and track their progress over time. The platform provides a secure and 
         intuitive way to document trades and gain valuable insights into trading behavior, helping traders 
         achieve better results.`,
    },
    {
        id: 8,
        img: '/images/projects/code.png',
        title: 'trade journal API',
        subtitle: 'backend powering the trade journal web app',
        codeLink: '',
        details: `Web Trade Journal's API is a powerful tool that allows traders to
         interact with the platform programmatically. The API is built on top of the popular 
         Node.js framework, Express, and uses MongoDB as the database backend.

        The API provides a range of endpoints that allow traders to interact with their 
        journals and access their trading data. Traders can log in using authentication 
        and create, read, update, and delete trades from their journal. The API also provides
         endpoints for retrieving data on a trader's win rate, best strategy, and other performance metrics.
        
        One of the key benefits of Web Trade Journal's API is its flexibility. Traders can use
         the API to integrate their trading data with other applications or services, allowing 
         for greater automation and analysis of their trading behavior. For example, a trader 
         could use the API to automatically log their trades from a third-party trading platform, 
         or integrate their trading data with a machine learning model for more advanced analysis.
        
        The API is designed to be highly scalable and robust. It uses a RESTful architecture, 
        which makes it easy for developers to build applications that can interact with it. 
        The API also supports authentication and rate limiting to ensure that traders' data is 
        kept secure and that the platform can handle high levels of traffic.
        
        Overall, Web Trade Journal's API is a powerful tool for traders who want to automate 
        and analyze their trading data. With its flexible architecture, robust design, and 
        integration with MongoDB and Express, the API provides traders with a powerful way to 
        interact with the platform and gain valuable insights into their trading performance.`,
    },
    {
        id: 9,
        img: '/images/projects/code.png',
        title: 'store filter API',
        subtitle: 'filtering store products on the backend',
        codeLink: '',
        details: `An API for filtering on an e-commerce store allows users to query
         the store's product catalog and filter the results based on specific criteria.
          This API typically uses a RESTful architecture, which means that it operates 
          using standard HTTP methods such as GET and POST.

        Users can access the API by sending HTTP requests to specific endpoints. For example,
         they may send a GET request to the endpoint /products, which would return a list of
          all products in the catalog. They could then filter these results by sending additional
           parameters in the request. For example, they may send a GET request to the
            endpoint /products?category=clothing&color=blue, which would return a list of 
            all clothing products that are available in blue.
        
        The API may support a range of filtering criteria, depending on the store's product 
        catalog. For example, it may allow users to filter products by category, brand, price 
        range, size, color, or any other product attribute that is relevant to the store.
        
        The API may also provide additional features to enhance the filtering experience. 
        For example, it may allow users to sort their results by price, popularity, or other 
        criteria. It may also support pagination, allowing users to browse through large catalogs 
        of products in a more manageable way.
        
        Overall, an API for filtering on an e-commerce store provides users with a flexible 
        and powerful way to query and filter the store's product catalog. By supporting a range 
        of filtering criteria and providing additional features such as sorting and pagination, 
        the API allows users to find the products they are looking for quickly and easily`,
    },
    {
        id: 10,
        img: '/images/projects/code.png',
        title: 'Webscraper for online store',
        subtitle: `Web scraper built for an online store's flash sale.`,
        codeLink: 'https://github.com/pappitito/Web-scraper-for-online-store',
        details: `A web scraper is a program that automatically retrieves
         and extracts data from websites, making it easier for users to 
         access the information they need. The individual created a program 
         that would automatically search through Jumia's search results for 
         the iPhone 13, and notify them when the flash sale price was
          available. This would save the individual time and effort,
           as they would no longer have to manually search for the phone,
            and would be alerted as soon as the price was lowered.

        The timing of the flash sale was unknown, making
         it difficult to know when to search for the phone. To address 
         this issue, the program was designed to scrape the website 
         periodically until the price had been lowered and the phone was 
         found. Once the iPhone 13 with the desired flash sale price was 
         located, the program would send an email to the individual with 
         the page link, allowing them to easily make the purchase.
        
        Overall, the creation of the web scraper helped to automate the 
        search process, making it more efficient and convenient for the
         individual. By using technology to their advantage, they were 
         able to stay ahead of the competition and secure the iPhone 13 
         at the flash sale price, without having to spend time and energy 
         searching for it manually.`,
    },
    {
        id: 11,
        img: '/images/projects/code.png',
        title: 'breast cancer diagnosis',
        subtitle: 'Machine learning model for detecting breast cancer using tensorflow',
        codeLink: 'https://github.com/pappitito/breast-cancer-diagnosis',
        details: `Breast cancer is a life-threatening disease that affects millions of people worldwide. Early detection of breast cancer is essential for successful treatment, and machine learning classifiers built with TensorFlow can help to achieve this goal.

        A machine learning classifier built with TensorFlow for breast cancer detection uses numerical data to distinguish between malignant and benign tumors. The data is collected from medical records of patients, and it typically includes information such as tumor size, shape, texture, and other medical factors.
        
        The machine learning classifier is trained on this numerical data, and it uses an artificial neural network to learn patterns and relationships between the data features and the tumor type. Once the classifier is trained, it can accurately predict whether a new tumor is malignant or benign based on the numerical features extracted from the medical records.
        
        The machine learning classifier built with TensorFlow provides several benefits over traditional diagnostic methods. Firstly, it can analyze a large volume of data quickly and accurately, which can save time and reduce the risk of errors. Secondly, it can identify patterns and relationships in the data that may be difficult or impossible for humans to detect, leading to more accurate diagnoses.
        
        Furthermore, machine learning classifiers can be continually improved with additional data, and they have the potential to evolve with new medical advancements. The ability to quickly and accurately detect breast cancer can lead to improved patient outcomes and ultimately save lives.
        
        In conclusion, machine learning classifiers built with TensorFlow can help in the early detection and diagnosis of breast cancer by analyzing numerical data extracted from medical records. As more data becomes available, these models will become even more accurate and valuable in the fight against breast cancer`,
    },
    {
        id: 12,
        img: '/images/projects/code.png',
        title: 'Railway Fault classifier',
        subtitle: 'Machine learning model for detecting faults on a railway using tensorflow',
        codeLink: 'https://github.com/pappitito/railway-fault-classifier-',
        details: `Railways are an important transportation infrastructure that requires constant maintenance to ensure safety and reliability. Detecting faults in railways is a challenging task that requires careful inspection by trained professionals. However, machine learning algorithms trained with images of good and faulty railways can help to automate this process.

        A railway fault detector that is trained with TensorFlow using images of good and faulty railways uses deep learning algorithms to identify defects in the rails, such as cracks, breaks, and deformations. The detector is trained on a dataset of images that includes both normal and faulty railways, with the faulty images annotated to indicate the location and type of fault.
        
        The machine learning algorithm uses convolutional neural networks (CNNs) to analyze the images and identify patterns that distinguish between normal and faulty rails. The CNNs can identify subtle differences in the images that may be difficult for humans to detect, leading to more accurate fault detection.
        
        Once the railway fault detector is trained using TensorFlow, it can be used to analyze images captured by sensors or cameras mounted on trains or inspection vehicles. The detector can quickly identify faults and send alerts to maintenance crews, allowing them to take immediate action to repair the problem.
        
        Automated railway fault detection using machine learning has several advantages over traditional inspection methods. It can reduce the need for manual inspections, saving time and reducing costs. Additionally, it can detect faults that may have gone unnoticed in the past, leading to improved safety and reliability of railways.
        
        In conclusion, a railway fault detector that is trained with TensorFlow using images of good and faulty railways can automate the process of detecting faults in railways, leading to improved safety and reliability. As more data becomes available, these models will become even more accurate and valuable in maintaining the integrity of railway infrastructure.`,
    },
    {
        id: 13,
        img: '/images/projects/code.png',
        title: 'Drybean classifier',
        subtitle: 'Machine learning model for classifying drybean into 7 categories using tensorflow',
        codeLink: 'https://github.com/pappitito/drybean-classifier-w-tensorflow',
        details: `A dry bean classifier trained with numerical data is a machine learning model built with TensorFlow that uses numerical features such as size, shape, color, and texture to identify different types of dry beans. The classifier is trained on a dataset of labeled images of different types of dry beans, with numerical features extracted from each image.

        The TensorFlow model uses supervised learning techniques such as neural networks to analyze the numerical features and identify patterns that distinguish between different types of dry beans. As the model continues to learn from the dataset, it becomes more accurate in identifying the different types of dry beans.
        
        Once the dry bean classifier is trained using TensorFlow, it can be used to analyze new images of dry beans and classify them into different types. This process can be automated, making it more efficient and cost-effective.
        
        Automated dry bean classification using TensorFlow has several advantages over traditional methods. It can reduce the need for manual inspection, saving time and reducing costs. Additionally, it can classify beans more accurately, leading to improved quality control and more efficient supply chain management.
        
        In conclusion, a dry bean classifier trained with numerical data using TensorFlow is a machine learning model that can accurately identify different types of dry beans based on numerical features such as size, shape, color, and texture. As more data becomes available, these models will continue to improve in their accuracy, making them an essential tool for identifying and classifying different types of dry beans.`,
    },
    
]